# =============================================================================
# CORTEZ3 - AUDITORÍA EXHAUSTIVA DE ARQUITECTURA DE SOFTWARE
# AI-Native MVP - Sistema de Enseñanza-Aprendizaje con IA Generativa
# =============================================================================
# Fecha: Diciembre 2025
# Auditor: Claude Code (Arquitecto de Software)
# Alcance: Backend, Frontend, Base de Datos, DevOps
# Total de Defectos Identificados: 114
# =============================================================================

RESUMEN EJECUTIVO
================================================================================
| Área       | CRÍTICO | ALTO | MEDIO | BAJO | TOTAL |
|------------|---------|------|-------|------|-------|
| Backend    |    2    |  15  |   15  |   2  |   34  |
| Frontend   |    2    |   9  |   25  |   4  |   40  |
| Database   |    3    |   5  |    6  |   4  |   18  |
| DevOps     |    4    |   6  |    5  |   7  |   22  |
|------------|---------|------|-------|------|-------|
| TOTAL      |   11    |  35  |   51  |  17  |  114  |
================================================================================

PRIORIDADES DE REMEDIACIÓN:
1. CRÍTICOS (11): Resolver inmediatamente antes de cualquier despliegue
2. ALTOS (35): Resolver en Sprint actual
3. MEDIOS (51): Planificar para próximo Sprint
4. BAJOS (17): Backlog técnico

================================================================================
SECCIÓN 1: BACKEND - DEFECTOS CRÍTICOS Y ALTOS
================================================================================

## 1.1 CRÍTICO: Ejecución de Código Arbitrario (Code Injection)
- Archivo: backend/api/routers/exercises.py
- Líneas: 340-370
- Severidad: CRITICAL
- Categoría: Seguridad

PROBLEMA:
La función `execute_python_code()` usa filtrado basado en strings para bloquear
funciones peligrosas, lo cual es fácilmente eludible con ofuscación:
- `e` + `val` + `()` evita el filtro de "eval"
- `__import__("os")` permite acceso al sistema operativo
- Los builtins restringidos son incompletos

CORRECCIÓN:
```python
# Usar RestrictedPython en lugar de filtrado de strings
from RestrictedPython import compile_restricted, safe_globals
from RestrictedPython.Eval import default_guarded_getiter, default_guarded_getitem

def execute_python_code_safe(code: str, timeout_seconds: int = 5) -> dict:
    """Ejecuta código Python en sandbox seguro."""
    try:
        byte_code = compile_restricted(code, '<user_code>', 'exec')

        safe_env = safe_globals.copy()
        safe_env['_getiter_'] = default_guarded_getiter
        safe_env['_getitem_'] = default_guarded_getitem
        safe_env['__builtins__'] = {
            'print': print,
            'len': len,
            'range': range,
            'str': str,
            'int': int,
            'float': float,
            'list': list,
            'dict': dict,
            'tuple': tuple,
            'set': set,
            'True': True,
            'False': False,
            'None': None,
        }

        # Ejecutar con timeout usando subprocess
        exec(byte_code, safe_env)
        return {"success": True, "output": safe_env.get('result')}
    except Exception as e:
        return {"success": False, "error": str(e)}
```

--------------------------------------------------------------------------------

## 1.2 CRÍTICO: JWT Secret Key Hardcodeado
- Archivo: backend/core/security.py
- Línea: 56
- Severidad: CRITICAL
- Categoría: Seguridad - Secrets Exposure

PROBLEMA:
```python
# ACTUAL (INSEGURO):
JWT_SECRET = os.getenv("JWT_SECRET_KEY", "dev-only-insecure-key-do-not-use-in-production-123456")
```

CORRECCIÓN:
```python
# CORREGIDO:
JWT_SECRET = os.getenv("JWT_SECRET_KEY")
if not JWT_SECRET:
    if os.getenv("ENVIRONMENT") == "production":
        raise RuntimeError("JWT_SECRET_KEY is required in production")
    else:
        import secrets
        JWT_SECRET = secrets.token_urlsafe(32)
        logger.warning(
            "JWT_SECRET_KEY not set, using auto-generated key. "
            "This is only acceptable in development."
        )
```

--------------------------------------------------------------------------------

## 1.3 ALTO: Rate Limiting Faltante en Endpoints Sensibles
- Archivo: backend/api/routers/exercises.py
- Línea: 389 (endpoint de ejecución de código)
- Severidad: HIGH
- Categoría: DOS Protection

PROBLEMA:
El endpoint POST /exercises/{id}/submit ejecuta código Python sin rate limiting.

CORRECCIÓN:
```python
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)

@router.post(
    "/{exercise_id}/submit",
    response_model=APIResponse[SubmissionResult],
)
@limiter.limit("5/minute")  # AGREGAR
async def submit_exercise(
    request: Request,  # AGREGAR para limiter
    exercise_id: str,
    submission: CodeSubmission,
    ...
):
```

--------------------------------------------------------------------------------

## 1.4 ALTO: CORS Misconfiguration
- Archivo: backend/api/main.py
- Líneas: 238-245
- Severidad: HIGH
- Categoría: Seguridad

PROBLEMA:
```python
# ACTUAL (INSEGURO):
allow_methods=["*"],  # Permite OPTIONS, TRACE, CONNECT
allow_headers=["*"],  # Permite cualquier header
```

CORRECCIÓN:
```python
# CORREGIDO:
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "PATCH", "OPTIONS"],
    allow_headers=["Content-Type", "Authorization", "X-Request-ID"],
    max_age=3600,  # Cache preflight por 1 hora
    expose_headers=["X-Request-ID", "X-Total-Count"],
)
```

--------------------------------------------------------------------------------

## 1.5 ALTO: Business Logic en Routers (Violación Clean Architecture)
- Archivos:
  - backend/api/routers/evaluations.py:155-220
  - backend/api/routers/exercises.py:340-370
  - backend/api/routers/reports.py:*
- Severidad: HIGH
- Categoría: Arquitectura

PROBLEMA:
Lógica de negocio compleja (llamadas LLM, scoring, ejecución de código) vive en
routers en lugar de la capa de servicios/agentes.

CORRECCIÓN:
Crear servicios dedicados:

```python
# backend/services/evaluation_service.py
class EvaluationService:
    def __init__(
        self,
        llm_provider: LLMProvider,
        trace_repo: TraceRepository,
        evaluation_repo: EvaluationRepository
    ):
        self.llm = llm_provider
        self.trace_repo = trace_repo
        self.evaluation_repo = evaluation_repo

    async def generate_evaluation(
        self,
        session_id: str,
        traces: List[CognitiveTrace]
    ) -> Evaluation:
        """Genera evaluación basada en trazas cognitivas."""
        # Mover lógica de evaluations.py:155-220 aquí
        ...

# backend/services/code_executor_service.py
class CodeExecutorService:
    def __init__(self, timeout: int = 5):
        self.timeout = timeout

    def execute_safely(self, code: str) -> ExecutionResult:
        """Ejecuta código en sandbox seguro."""
        # Mover lógica de exercises.py:340-370 aquí
        ...
```

```python
# En router (evaluations.py):
@router.post("/{session_id}/generate")
async def generate_evaluation(
    session_id: str,
    evaluation_service: EvaluationService = Depends(get_evaluation_service)
):
    return await evaluation_service.generate_evaluation(session_id)
```

--------------------------------------------------------------------------------

## 1.6 ALTO: N+1 Queries en Repositorios
- Archivo: backend/database/repositories.py
- Líneas: 263-292
- Severidad: HIGH
- Categoría: Performance

PROBLEMA:
```python
# ACTUAL - Carga lazy, genera N+1 queries:
def get_by_student(self, student_id: str) -> List[SessionDB]:
    return self.db.query(SessionDB).filter_by(student_id=student_id).all()
# Luego acceder a session.traces genera query adicional por cada session
```

CORRECCIÓN:
```python
from sqlalchemy.orm import selectinload

def get_by_student(
    self,
    student_id: str,
    eager_load: bool = True
) -> List[SessionDB]:
    """
    Obtiene sesiones de un estudiante.

    Args:
        student_id: ID del estudiante
        eager_load: Si True, precarga traces y risks (evita N+1)
    """
    query = self.db.query(SessionDB).filter_by(student_id=student_id)

    if eager_load:
        query = query.options(
            selectinload(SessionDB.traces),
            selectinload(SessionDB.risks),
            selectinload(SessionDB.evaluations)
        )

    return query.order_by(SessionDB.created_at.desc()).all()
```

--------------------------------------------------------------------------------

## 1.7 ALTO: Paginación Sin Defaults
- Archivos: backend/api/routers/risks.py, traces.py
- Severidad: HIGH
- Categoría: Performance

PROBLEMA:
List endpoints pueden retornar miles de registros sin límite.

CORRECCIÓN:
```python
from fastapi import Query

@router.get("/traces")
async def get_traces(
    session_id: str,
    limit: int = Query(default=100, le=1000, description="Max 1000"),
    offset: int = Query(default=0, ge=0),
    db: Session = Depends(get_db)
) -> PaginatedResponse[CognitiveTraceResponse]:
    total = trace_repo.count_by_session(session_id)
    traces = trace_repo.get_by_session(session_id, limit=limit, offset=offset)

    return PaginatedResponse(
        data=traces,
        total=total,
        limit=limit,
        offset=offset,
        has_more=offset + len(traces) < total
    )
```

--------------------------------------------------------------------------------

## 1.8 ALTO: Risk Analysis Síncrono Bloquea Response
- Archivo: backend/core/ai_gateway.py
- Líneas: 414, 1045-1226
- Severidad: HIGH
- Categoría: Performance

PROBLEMA:
`_analyze_risks_async()` se ejecuta sincrónicamente y bloquea la respuesta.

CORRECCIÓN:
```python
from fastapi import BackgroundTasks

# En ai_gateway.py:
async def process_interaction(
    self,
    session_id: str,
    prompt: str,
    background_tasks: BackgroundTasks,
    ...
) -> InteractionResponse:
    # Procesar interacción principal
    response = await self._generate_response(...)

    # Analizar riesgos en background (no bloquea respuesta)
    background_tasks.add_task(
        self._analyze_risks_background,
        session_id=session_id,
        interaction_id=response.id,
        prompt=prompt,
        response=response.content
    )

    return response

async def _analyze_risks_background(
    self,
    session_id: str,
    interaction_id: str,
    prompt: str,
    response: str
):
    """Analiza riesgos en background después de enviar respuesta."""
    try:
        risks = await self._analyze_risks_async(...)
        await self.risk_repo.create_batch(risks)
    except Exception as e:
        logger.error(f"Background risk analysis failed: {e}")
```

--------------------------------------------------------------------------------

## 1.9 ALTO: Respuestas API Inconsistentes
- Archivos: simulators.py, interactions.py, ai_gateway.py
- Severidad: HIGH
- Categoría: API Contract

PROBLEMA:
Diferentes formatos de respuesta:
- Simulators: `{"message": "...", "metadata": {}}`
- Gateway: `{"response": "...", "blocked": true}`
- Sessions: `{"data": {...}}`

CORRECCIÓN:
Aplicar APIResponse[T] wrapper en TODOS los endpoints:

```python
# En cada router:
@router.post("", response_model=APIResponse[SimulatorResponse])
async def interact(...) -> APIResponse[SimulatorResponse]:
    result = await simulator.interact(...)
    return APIResponse(
        success=True,
        data=SimulatorResponse(
            message=result.message,
            metadata=result.metadata
        ),
        message="Interaction processed"
    )
```

--------------------------------------------------------------------------------

## 1.10 ALTO: Input Size Limits No Aplicados
- Archivo: backend/api/routers/interactions.py
- Líneas: 53-58
- Severidad: HIGH
- Categoría: DOS/Input Validation

PROBLEMA:
Constantes definidas pero no aplicadas:
- PROMPT_MAX_LENGTH = 5000
- CONTEXT_MAX_SIZE_BYTES = 100000

CORRECCIÓN:
```python
from pydantic import validator, Field
from backend.core.constants import PROMPT_MAX_LENGTH, CONTEXT_MAX_SIZE_BYTES

class InteractionRequest(BaseModel):
    session_id: str = Field(..., min_length=1, max_length=36)
    prompt: str = Field(..., min_length=1, max_length=PROMPT_MAX_LENGTH)
    context: Optional[Dict[str, Any]] = None

    @validator('context')
    def validate_context_size(cls, v):
        if v is not None:
            import json
            size = len(json.dumps(v).encode('utf-8'))
            if size > CONTEXT_MAX_SIZE_BYTES:
                raise ValueError(
                    f"Context exceeds {CONTEXT_MAX_SIZE_BYTES} bytes limit"
                )
        return v
```

================================================================================
SECCIÓN 2: FRONTEND - DEFECTOS CRÍTICOS Y ALTOS
================================================================================

## 2.1 CRÍTICO: Componentes Demasiado Grandes (>200 líneas)
- Archivos:
  - frontEnd/src/pages/TutorPage.tsx (478 líneas)
  - frontEnd/src/pages/ExercisesPageNew.tsx (387 líneas)
- Severidad: CRITICAL
- Categoría: Componentes

PROBLEMA:
Componentes monolíticos que manejan múltiples responsabilidades.

CORRECCIÓN para TutorPage.tsx:
```typescript
// Dividir en componentes más pequeños:

// frontEnd/src/features/tutor/components/TutorChatArea.tsx
export const TutorChatArea: React.FC<{
  messages: ChatMessage[];
  onSend: (message: string) => void;
  loading: boolean;
}> = ({ messages, onSend, loading }) => {
  // Lógica del área de chat
};

// frontEnd/src/features/tutor/components/TutorHeader.tsx
export const TutorHeader: React.FC<{
  session: Session | null;
  mode: TutorMode;
  onModeChange: (mode: TutorMode) => void;
}> = ({ session, mode, onModeChange }) => {
  // Header con selector de modo
};

// frontEnd/src/features/tutor/components/TutorAnalysisPanel.tsx
export const TutorAnalysisPanel: React.FC<{
  sessionId: string;
  showTraceability: boolean;
  showRisks: boolean;
}> = ({ sessionId, showTraceability, showRisks }) => {
  // Panel lateral con análisis
};

// frontEnd/src/pages/TutorPage.tsx (refactorizado)
import { TutorChatArea } from '@/features/tutor/components/TutorChatArea';
import { TutorHeader } from '@/features/tutor/components/TutorHeader';
import { TutorAnalysisPanel } from '@/features/tutor/components/TutorAnalysisPanel';
import { useTutorSession } from '@/features/tutor/hooks/useTutorSession';

export default function TutorPage() {
  const { session, messages, loading, sendMessage, mode, setMode } = useTutorSession();

  return (
    <div className="tutor-page">
      <TutorHeader session={session} mode={mode} onModeChange={setMode} />
      <div className="tutor-content">
        <TutorChatArea messages={messages} onSend={sendMessage} loading={loading} />
        <TutorAnalysisPanel sessionId={session?.id} />
      </div>
    </div>
  );
}
```

--------------------------------------------------------------------------------

## 2.2 CRÍTICO: Duplicación de Estado Global (Auth)
- Archivos:
  - frontEnd/src/contexts/AuthContext.tsx
  - frontEnd/src/core/context/AppContext.tsx
- Severidad: CRITICAL
- Categoría: State Management

PROBLEMA:
Dos contextos separados manejan estado de usuario, causando inconsistencias.

CORRECCIÓN:
```typescript
// Consolidar en un solo contexto:
// frontEnd/src/contexts/AuthContext.tsx

interface AuthState {
  user: User | null;
  isAuthenticated: boolean;
  isLoading: boolean;
  token: string | null;
}

interface AuthContextValue extends AuthState {
  login: (credentials: LoginCredentials) => Promise<void>;
  logout: () => void;
  refreshToken: () => Promise<void>;
}

export const AuthContext = createContext<AuthContextValue | null>(null);

export const AuthProvider: React.FC<{ children: ReactNode }> = ({ children }) => {
  const [state, dispatch] = useReducer(authReducer, initialState);

  // ... implementación

  return (
    <AuthContext.Provider value={{ ...state, login, logout, refreshToken }}>
      {children}
    </AuthContext.Provider>
  );
};

// Eliminar AppContext o hacer que solo maneje estado de UI (no auth)
// frontEnd/src/core/context/AppContext.tsx
interface AppState {
  theme: 'light' | 'dark';
  sidebarOpen: boolean;
  notifications: Notification[];
}

// NO incluir user aquí - usar AuthContext para eso
```

--------------------------------------------------------------------------------

## 2.3 ALTO: Monaco Editor Sin Lazy Loading
- Archivo: frontEnd/src/pages/ExerciseDetailPage.tsx
- Línea: 5
- Severidad: HIGH
- Categoría: Performance

PROBLEMA:
Monaco Editor importado directamente añade ~3MB al bundle.

CORRECCIÓN:
```typescript
import React, { lazy, Suspense } from 'react';

// Lazy load Monaco Editor
const Editor = lazy(() => import('@monaco-editor/react'));

// Componente de fallback
const EditorSkeleton = () => (
  <div className="editor-skeleton">
    <div className="skeleton-line" />
    <div className="skeleton-line" />
    <div className="skeleton-line" />
  </div>
);

export default function ExerciseDetailPage() {
  return (
    <div className="exercise-detail">
      <Suspense fallback={<EditorSkeleton />}>
        <Editor
          height="400px"
          language="python"
          theme="vs-dark"
          value={code}
          onChange={setCode}
        />
      </Suspense>
    </div>
  );
}
```

--------------------------------------------------------------------------------

## 2.4 ALTO: Error Typing Inconsistente
- Archivos: TutorPage.tsx:152, SimulatorsHub.tsx:154, RiskAnalyzer.tsx:102
- Severidad: HIGH
- Categoría: TypeScript

PROBLEMA:
Diferentes patrones de manejo de errores con casting inseguro.

CORRECCIÓN:
```typescript
// frontEnd/src/utils/error.ts
export interface AppError {
  message: string;
  code?: string;
  status?: number;
  details?: Record<string, unknown>;
}

export function extractErrorMessage(error: unknown): string {
  if (error instanceof Error) {
    return error.message;
  }
  if (typeof error === 'string') {
    return error;
  }
  if (error && typeof error === 'object') {
    const err = error as Record<string, unknown>;
    if ('message' in err && typeof err.message === 'string') {
      return err.message;
    }
    if ('response' in err && err.response && typeof err.response === 'object') {
      const response = err.response as Record<string, unknown>;
      if ('data' in response && response.data && typeof response.data === 'object') {
        const data = response.data as Record<string, unknown>;
        if ('message' in data && typeof data.message === 'string') {
          return data.message;
        }
      }
    }
  }
  return 'An unexpected error occurred';
}

export function isAppError(error: unknown): error is AppError {
  return (
    error !== null &&
    typeof error === 'object' &&
    'message' in error &&
    typeof (error as AppError).message === 'string'
  );
}

// Uso en componentes:
try {
  await submitExercise(code);
} catch (error) {
  const message = extractErrorMessage(error);
  showToast(message, 'error');
}
```

--------------------------------------------------------------------------------

## 2.5 ALTO: useCallback Faltante en Handlers
- Archivos:
  - SimulatorsHub.tsx:130 (handleSend)
  - RiskAnalyzer.tsx:109 (analyzeRisks)
- Severidad: HIGH
- Categoría: React Best Practices

PROBLEMA:
Funciones recreadas en cada render causan re-renders innecesarios.

CORRECCIÓN para SimulatorsHub.tsx:
```typescript
const handleSend = useCallback(async () => {
  if (!prompt.trim() || loading || !selectedSimulator) return;

  setLoading(true);
  try {
    const response = await simulatorsService.interact({
      simulator_type: selectedSimulator,
      message: prompt,
      context: { previous_messages: conversation }
    });

    setConversation(prev => [
      ...prev,
      { role: 'user', content: prompt },
      { role: 'assistant', content: response.message }
    ]);
    setPrompt('');
  } catch (error) {
    showToast(extractErrorMessage(error), 'error');
  } finally {
    setLoading(false);
  }
}, [prompt, loading, selectedSimulator, conversation, showToast]);
```

--------------------------------------------------------------------------------

## 2.6 ALTO: Request Cancellation Faltante en Services
- Archivo: frontEnd/src/core/http/HttpClient.ts
- Severidad: HIGH
- Categoría: Service Layer

PROBLEMA:
Métodos estándar get/post no soportan cancellation tokens.

CORRECCIÓN:
```typescript
// frontEnd/src/core/http/HttpClient.ts
export class HttpClient {
  async get<T>(
    url: string,
    config?: AxiosRequestConfig,
    signal?: AbortSignal
  ): Promise<T> {
    const response = await this.client.get<T>(url, {
      ...config,
      signal
    });
    return response.data;
  }

  async post<T, D = unknown>(
    url: string,
    data?: D,
    config?: AxiosRequestConfig,
    signal?: AbortSignal
  ): Promise<T> {
    const response = await this.client.post<T>(url, data, {
      ...config,
      signal
    });
    return response.data;
  }
}

// Uso en componentes:
useEffect(() => {
  const controller = new AbortController();

  const fetchData = async () => {
    try {
      const data = await httpClient.get('/sessions', {}, controller.signal);
      setSessions(data);
    } catch (error) {
      if (!controller.signal.aborted) {
        showToast(extractErrorMessage(error), 'error');
      }
    }
  };

  fetchData();

  return () => controller.abort();
}, []);
```

--------------------------------------------------------------------------------

## 2.7 ALTO: Estado de Editor No Persistido
- Archivo: frontEnd/src/pages/ExerciseDetailPage.tsx
- Línea: 23
- Severidad: HIGH
- Categoría: State Management

PROBLEMA:
Código en el editor se pierde al navegar o refrescar.

CORRECCIÓN:
```typescript
const STORAGE_KEY = 'exercise_code_';

export default function ExerciseDetailPage() {
  const { exerciseId } = useParams<{ exerciseId: string }>();

  // Cargar código guardado
  const [code, setCode] = useState<string>(() => {
    const saved = sessionStorage.getItem(`${STORAGE_KEY}${exerciseId}`);
    return saved || exercise?.starterCode || '';
  });

  // Guardar código en cada cambio
  const handleCodeChange = useCallback((value: string | undefined) => {
    const newCode = value || '';
    setCode(newCode);
    sessionStorage.setItem(`${STORAGE_KEY}${exerciseId}`, newCode);
  }, [exerciseId]);

  // Limpiar al enviar exitosamente
  const handleSubmitSuccess = useCallback(() => {
    sessionStorage.removeItem(`${STORAGE_KEY}${exerciseId}`);
  }, [exerciseId]);

  return (
    <Editor
      value={code}
      onChange={handleCodeChange}
      // ...
    />
  );
}
```

--------------------------------------------------------------------------------

## 2.8 MEDIO: Object Literals en JSX Props
- Archivo: frontEnd/src/features/simulators/pages/SimulatorsHub.tsx
- Líneas: 147-151
- Severidad: MEDIUM
- Categoría: React Best Practices

PROBLEMA:
```typescript
// Crea nuevo objeto en cada render:
context={{ previous_messages: conversation.map(...) }}
```

CORRECCIÓN:
```typescript
// Memoizar el contexto:
const conversationContext = useMemo(() => ({
  previous_messages: conversation.map(msg => ({
    role: msg.role,
    content: msg.content
  }))
}), [conversation]);

// Usar en JSX:
context={conversationContext}
```

--------------------------------------------------------------------------------

## 2.9 MEDIO: Stats Array Sin Memoización
- Archivo: frontEnd/src/pages/DashboardPage.tsx
- Líneas: 74-112
- Severidad: MEDIUM
- Categoría: React Best Practices

PROBLEMA:
Array de stats recreado en cada render con valores calculados.

CORRECCIÓN:
```typescript
const stats = useMemo(() => [
  {
    label: 'Sesiones Activas',
    value: activeSessions,
    icon: 'activity',
    color: 'blue'
  },
  {
    label: 'Sesiones Completadas',
    value: completedSessions,
    icon: 'check-circle',
    color: 'green'
  },
  {
    label: 'Total Interacciones',
    value: totalInteractions,
    icon: 'message-circle',
    color: 'purple'
  }
], [activeSessions, completedSessions, totalInteractions]);
```

================================================================================
SECCIÓN 3: BASE DE DATOS - DEFECTOS CRÍTICOS Y ALTOS
================================================================================

## 3.1 CRÍTICO: StudentProfileRepository Faltante
- Archivo: backend/database/repositories.py
- Severidad: CRITICAL
- Categoría: Missing CRUD Methods

PROBLEMA:
El modelo StudentProfileDB existe pero no tiene repositorio dedicado.

CORRECCIÓN:
```python
# Agregar a backend/database/repositories.py:

class StudentProfileRepository:
    """Repositorio para gestión de perfiles de estudiante."""

    def __init__(self, db_session: Session):
        self.db = db_session

    def create(
        self,
        student_id: str,
        user_id: Optional[str] = None,
        name: str = "",
        email: str = "",
        academic_program: Optional[str] = None,
        current_semester: Optional[int] = None
    ) -> StudentProfileDB:
        """Crea un nuevo perfil de estudiante."""
        profile = StudentProfileDB(
            id=str(uuid4()),
            student_id=student_id,
            user_id=user_id,
            name=name,
            email=email,
            academic_program=academic_program,
            current_semester=current_semester,
            created_at=utc_now(),
            updated_at=utc_now()
        )
        self.db.add(profile)
        self.db.commit()
        self.db.refresh(profile)
        return profile

    def get_by_id(self, id: str) -> Optional[StudentProfileDB]:
        """Obtiene perfil por ID."""
        return self.db.query(StudentProfileDB).filter(
            StudentProfileDB.id == id
        ).first()

    def get_by_student_id(self, student_id: str) -> Optional[StudentProfileDB]:
        """Obtiene perfil por student_id."""
        return self.db.query(StudentProfileDB).filter(
            StudentProfileDB.student_id == student_id
        ).first()

    def get_by_user_id(self, user_id: str) -> Optional[StudentProfileDB]:
        """Obtiene perfil por user_id (usuario autenticado)."""
        return self.db.query(StudentProfileDB).filter(
            StudentProfileDB.user_id == user_id
        ).first()

    def get_all(self, limit: int = 100, offset: int = 0) -> List[StudentProfileDB]:
        """Lista todos los perfiles con paginación."""
        return self.db.query(StudentProfileDB)\
            .order_by(StudentProfileDB.created_at.desc())\
            .offset(offset)\
            .limit(limit)\
            .all()

    def update_analytics(
        self,
        student_id: str,
        total_sessions: int,
        avg_ai_dependency: float,
        identified_risks: List[str],
        competency_evolution: Dict[str, Any]
    ) -> Optional[StudentProfileDB]:
        """Actualiza métricas analíticas del estudiante."""
        profile = self.get_by_student_id(student_id)
        if not profile:
            return None

        profile.total_sessions = total_sessions
        profile.avg_ai_dependency = avg_ai_dependency
        profile.identified_risks = identified_risks
        profile.competency_evolution = competency_evolution
        profile.updated_at = utc_now()

        self.db.commit()
        self.db.refresh(profile)
        return profile

    def get_at_risk_students(
        self,
        ai_dependency_threshold: float = 0.7
    ) -> List[StudentProfileDB]:
        """Obtiene estudiantes con alto riesgo de dependencia de IA."""
        return self.db.query(StudentProfileDB).filter(
            StudentProfileDB.avg_ai_dependency >= ai_dependency_threshold
        ).order_by(StudentProfileDB.avg_ai_dependency.desc()).all()
```

--------------------------------------------------------------------------------

## 3.2 CRÍTICO: CASCADE DELETE Faltante en ForeignKeys
- Archivo: backend/database/models.py
- Líneas: 905, 973, 1093
- Severidad: CRITICAL
- Categoría: Data Integrity

PROBLEMA:
Tres modelos tienen FK a sessions sin ondelete="CASCADE":
- InterviewSessionDB.session_id
- IncidentSimulationDB.session_id
- SimulatorEventDB.session_id

CORRECCIÓN:
```python
# InterviewSessionDB (línea 905):
session_id = Column(
    String(36),
    ForeignKey("sessions.id", ondelete="CASCADE"),  # AGREGAR ondelete
    nullable=False,
    index=True
)

# IncidentSimulationDB (línea 973):
session_id = Column(
    String(36),
    ForeignKey("sessions.id", ondelete="CASCADE"),  # AGREGAR ondelete
    nullable=False,
    index=True
)

# SimulatorEventDB (línea 1093):
session_id = Column(
    String(36),
    ForeignKey("sessions.id", ondelete="CASCADE"),  # AGREGAR ondelete
    nullable=False,
    index=True
)
```

--------------------------------------------------------------------------------

## 3.3 CRÍTICO: ondelete Inconsistente en FKs
- Archivo: backend/database/models.py
- Líneas: 85, 873
- Severidad: CRITICAL
- Categoría: Data Integrity

PROBLEMA:
- Línea 85: user_id FK sin ondelete explícito
- Línea 873: remediation_plan_id FK sin ondelete

CORRECCIÓN:
```python
# SessionDB.user_id (línea 85):
user_id = Column(
    String(36),
    ForeignKey("users.id", ondelete="SET NULL"),  # Mantener sesiones si user se borra
    nullable=True,  # Ya es nullable
    index=True
)

# RiskAlertDB.remediation_plan_id (línea 873):
remediation_plan_id = Column(
    String(36),
    ForeignKey("remediation_plans.id", ondelete="SET NULL"),  # AGREGAR
    nullable=True,
    index=True
)
```

--------------------------------------------------------------------------------

## 3.4 ALTO: Index Compuesto Faltante en RiskDB
- Archivo: backend/database/models.py
- Líneas: 348-358
- Severidad: HIGH
- Categoría: Query Performance

PROBLEMA:
Falta index en (session_id, dimension) para consultas de análisis 5D.

CORRECCIÓN:
```python
class RiskDB(Base):
    __tablename__ = "risks"

    # ... campos existentes ...

    __table_args__ = (
        Index('idx_student_resolved', 'student_id', 'resolved'),
        Index('idx_level_created', 'risk_level', 'created_at'),
        Index('idx_student_activity_dimension', 'student_id', 'activity_id', 'dimension'),
        Index('idx_risk_session_type', 'session_id', 'risk_type'),
        Index('idx_risk_session_dimension', 'session_id', 'dimension'),  # NUEVO
    )
```

--------------------------------------------------------------------------------

## 3.5 ALTO: Index Faltante en CognitiveTraceDB.activity_id
- Archivo: backend/database/models.py
- Líneas: 179, 285-299
- Severidad: HIGH
- Categoría: Query Performance

PROBLEMA:
activity_id solo está en índices compuestos, no individual.

CORRECCIÓN:
```python
class CognitiveTraceDB(Base):
    __tablename__ = "cognitive_traces"

    __table_args__ = (
        # ... índices existentes ...
        Index('idx_trace_activity_id', 'activity_id'),  # NUEVO - para reportes por actividad
    )
```

--------------------------------------------------------------------------------

## 3.6 ALTO: N+1 Query en get_critical_risks()
- Archivo: backend/database/repositories.py
- Líneas: 744-758
- Severidad: HIGH
- Categoría: N+1 Query

PROBLEMA:
joinedload solo carga sessions, no las relaciones anidadas.

CORRECCIÓN:
```python
def get_critical_risks(
    self,
    student_id: Optional[str] = None,
    load_session_relations: bool = True
) -> List[RiskDB]:
    """
    Obtiene riesgos críticos con eager loading de relaciones.

    Args:
        student_id: Filtrar por estudiante (opcional)
        load_session_relations: Si True, precarga traces y risks de la sesión
    """
    query = self.db.query(RiskDB).filter(
        RiskDB.risk_level == "critical",
        RiskDB.resolved == False
    )

    if student_id:
        query = query.filter(RiskDB.student_id == student_id)

    if load_session_relations:
        query = query.options(
            selectinload(RiskDB.session).selectinload(SessionDB.traces),
            selectinload(RiskDB.session).selectinload(SessionDB.evaluations)
        )
    else:
        query = query.options(joinedload(RiskDB.session))

    return query.order_by(RiskDB.created_at.desc()).all()
```

--------------------------------------------------------------------------------

## 3.7 ALTO: Batch Loading Method Faltante
- Archivo: backend/database/repositories.py
- Severidad: HIGH
- Categoría: N+1 Prevention

PROBLEMA:
No existe método para cargar trazas por múltiples pares (student_id, activity_id).

CORRECCIÓN:
```python
def get_by_student_activity_pairs(
    self,
    pairs: List[Tuple[str, str]]
) -> Dict[Tuple[str, str], List[CognitiveTraceDB]]:
    """
    Carga trazas para múltiples combinaciones student-activity en una query.

    Args:
        pairs: Lista de tuplas (student_id, activity_id)

    Returns:
        Diccionario mapeando cada par a su lista de trazas
    """
    if not pairs:
        return {}

    # Construir filtro OR para todas las combinaciones
    from sqlalchemy import or_, and_

    filters = [
        and_(
            CognitiveTraceDB.student_id == student_id,
            CognitiveTraceDB.activity_id == activity_id
        )
        for student_id, activity_id in pairs
    ]

    traces = self.db.query(CognitiveTraceDB).filter(
        or_(*filters)
    ).order_by(
        CognitiveTraceDB.student_id,
        CognitiveTraceDB.activity_id,
        CognitiveTraceDB.created_at
    ).all()

    # Agrupar por par
    result: Dict[Tuple[str, str], List[CognitiveTraceDB]] = {
        pair: [] for pair in pairs
    }

    for trace in traces:
        key = (trace.student_id, trace.activity_id)
        if key in result:
            result[key].append(trace)

    return result
```

--------------------------------------------------------------------------------

## 3.8 MEDIO: Unique Constraint Faltante en LTISessionDB
- Archivo: backend/database/models.py
- Líneas: 1120-1168
- Severidad: MEDIUM
- Categoría: Data Integrity

PROBLEMA:
No hay constraint único para (deployment_id, lti_user_id, resource_link_id).

CORRECCIÓN:
```python
class LTISessionDB(Base):
    __tablename__ = "lti_sessions"

    __table_args__ = (
        Index('idx_lti_session_user', 'lti_user_id'),
        Index('idx_lti_session_resource', 'resource_link_id'),
        Index('idx_lti_session_native', 'session_id'),
        # NUEVO: Unique constraint
        Index(
            'idx_lti_unique_user_resource',
            'deployment_id',
            'lti_user_id',
            'resource_link_id',
            unique=True
        ),
    )
```

================================================================================
SECCIÓN 4: DEVOPS - DEFECTOS CRÍTICOS Y ALTOS
================================================================================

## 4.1 CRÍTICO: Credenciales Grafana Hardcodeadas
- Archivo: devops/monitoring/docker-compose.monitoring.yml
- Líneas: 74-75
- Severidad: CRITICAL
- Categoría: Security

PROBLEMA:
```yaml
# ACTUAL (INSEGURO):
- GF_SECURITY_ADMIN_USER=admin
- GF_SECURITY_ADMIN_PASSWORD=admin
```

CORRECCIÓN:
```yaml
# CORREGIDO:
- GF_SECURITY_ADMIN_USER=${GRAFANA_USER:-admin}
- GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:?GRAFANA_PASSWORD is required}
```

--------------------------------------------------------------------------------

## 4.2 CRÍTICO: Puerto PostgreSQL Expuesto
- Archivo: docker-compose.yml
- Líneas: 112-113
- Severidad: CRITICAL
- Categoría: Network Security

PROBLEMA:
```yaml
# ACTUAL - Expone DB a la red del host:
ports:
  - "5432:5432"
```

CORRECCIÓN:
```yaml
# Solo exponer en desarrollo usando profiles:
services:
  postgres:
    # ... configuración existente ...

    # Remover ports en producción, solo usar expose:
    expose:
      - "5432"  # Solo accesible desde red interna Docker

    # En desarrollo, agregar con profile:
    profiles:
      - dev

# Agregar servicio adicional para desarrollo:
  postgres-dev:
    extends:
      service: postgres
    ports:
      - "5432:5432"  # Solo en desarrollo
    profiles:
      - dev
```

--------------------------------------------------------------------------------

## 4.3 CRÍTICO: Redis Password Visible en Comandos
- Archivo: docker-compose.yml
- Líneas: 188-199
- Severidad: CRITICAL
- Categoría: Secrets Exposure

PROBLEMA:
Password visible en `docker ps`, logs y `/proc`.

CORRECCIÓN:
```yaml
# 1. Crear archivo redis.conf:
# redis.conf
requirepass ${REDIS_PASSWORD}
appendonly yes
appendfsync everysec
maxmemory 256mb
maxmemory-policy allkeys-lru

# 2. Modificar docker-compose.yml:
redis:
  image: redis:7.2-alpine
  container_name: ai-native-redis
  command: ["redis-server", "/etc/redis/redis.conf"]
  volumes:
    - redis_data:/data
    - ./redis.conf:/etc/redis/redis.conf:ro
  environment:
    - REDIS_PASSWORD=${REDIS_PASSWORD:?required}
  # Password ya no está en command line
```

--------------------------------------------------------------------------------

## 4.4 CRÍTICO: /metrics Endpoint Sin Autenticación
- Archivo: backend/api/routers/metrics.py
- Severidad: CRITICAL
- Categoría: Security

PROBLEMA:
Métricas de Prometheus expuestas públicamente.

CORRECCIÓN:
```python
# backend/api/routers/metrics.py
import os
from fastapi import Header, HTTPException

PROMETHEUS_TOKEN = os.getenv("PROMETHEUS_API_TOKEN")

@router.get("/metrics")
async def metrics(
    x_prometheus_token: str = Header(
        None,
        description="Token for Prometheus scraping"
    )
):
    """
    Prometheus metrics endpoint.

    Requires X-Prometheus-Token header in production.
    """
    if os.getenv("ENVIRONMENT") == "production":
        if not PROMETHEUS_TOKEN:
            raise HTTPException(
                status_code=500,
                detail="PROMETHEUS_API_TOKEN not configured"
            )
        if x_prometheus_token != PROMETHEUS_TOKEN:
            raise HTTPException(
                status_code=403,
                detail="Invalid metrics token"
            )

    # Generar métricas...
    return Response(
        content=generate_latest(REGISTRY),
        media_type=CONTENT_TYPE_LATEST
    )
```

```yaml
# prometheus.yml - agregar autenticación:
- job_name: 'ai-native-api'
  scrape_interval: 15s
  metrics_path: '/metrics'

  # Autenticación via header
  authorization:
    type: Bearer
    credentials_file: /etc/prometheus/api-token.txt

  static_configs:
    - targets: ['api:8000']
```

--------------------------------------------------------------------------------

## 4.5 ALTO: Alert Rules No Cargadas en Prometheus
- Archivo: prometheus.yml
- Líneas: 38-40
- Severidad: HIGH
- Categoría: Monitoring

PROBLEMA:
prometheus-alerts.yml existe pero está comentado en configuración.

CORRECCIÓN:
```yaml
# prometheus.yml:
global:
  scrape_interval: 15s
  evaluation_interval: 15s

# DESCOMENTAR:
rule_files:
  - '/etc/prometheus/alerts/*.yml'

alerting:
  alertmanagers:
    - static_configs:
        - targets: ['alertmanager:9093']

# ... resto de configuración ...
```

```yaml
# docker-compose.yml - montar archivos de alertas:
prometheus:
  volumes:
    - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
    - ./prometheus-alerts.yml:/etc/prometheus/alerts/alerts.yml:ro  # AGREGAR
    - prometheus_data:/prometheus
```

--------------------------------------------------------------------------------

## 4.6 ALTO: Network Segmentation Faltante
- Archivo: docker-compose.yml
- Severidad: HIGH
- Categoría: Network Security

PROBLEMA:
Todos los servicios en la misma red Docker.

CORRECCIÓN:
```yaml
networks:
  # Red principal para servicios de producción
  core:
    driver: bridge
    name: ai-native-core

  # Red para herramientas de debug (pgAdmin, Redis Commander)
  debug:
    driver: bridge
    name: ai-native-debug

  # Red para monitoreo (Prometheus, Grafana)
  monitoring:
    driver: bridge
    name: ai-native-monitoring

services:
  api:
    networks:
      - core
      - monitoring  # Para que Prometheus pueda scrapearlo

  postgres:
    networks:
      - core

  redis:
    networks:
      - core

  ollama:
    networks:
      - core

  pgadmin:
    networks:
      - debug
      - core  # Necesita acceso a postgres
    profiles:
      - debug

  redis-commander:
    networks:
      - debug
      - core  # Necesita acceso a redis
    profiles:
      - debug

  prometheus:
    networks:
      - monitoring
      - core  # Necesita acceso a api para métricas
    profiles:
      - monitoring

  grafana:
    networks:
      - monitoring
    profiles:
      - monitoring
```

--------------------------------------------------------------------------------

## 4.7 ALTO: TLS Staging en Kubernetes Ingress
- Archivo: devops/kubernetes/staging/08-ingress.yaml
- Línea: 8
- Severidad: HIGH
- Categoría: Security

PROBLEMA:
```yaml
# ACTUAL - Usa certificados staging (no confiables):
cert-manager.io/cluster-issuer: letsencrypt-staging
```

CORRECCIÓN:
```yaml
# PRODUCCIÓN:
metadata:
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"

# Crear ClusterIssuer de producción:
---
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: letsencrypt-prod
spec:
  acme:
    server: https://acme-v02.api.letsencrypt.org/directory
    email: admin@your-domain.com
    privateKeySecretRef:
      name: letsencrypt-prod
    solvers:
    - http01:
        ingress:
          class: nginx
```

--------------------------------------------------------------------------------

## 4.8 ALTO: Redis Health Check Sin start_period
- Archivo: docker-compose.yml
- Líneas: 200-205
- Severidad: HIGH
- Categoría: Reliability

PROBLEMA:
Health check puede fallar durante startup.

CORRECCIÓN:
```yaml
redis:
  healthcheck:
    test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
    interval: 10s
    timeout: 3s
    retries: 5
    start_period: 10s  # AGREGAR - dar tiempo a Redis para iniciar
```

--------------------------------------------------------------------------------

## 4.9 MEDIO: SecurityContext Faltante en Kubernetes
- Archivo: devops/kubernetes/staging/06-backend.yaml
- Severidad: MEDIUM
- Categoría: Security

PROBLEMA:
Contenedores pueden ejecutar como root.

CORRECCIÓN:
```yaml
spec:
  template:
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 1000

      containers:
      - name: backend
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 1000
          capabilities:
            drop:
              - ALL

        volumeMounts:
        - name: tmp
          mountPath: /tmp
        - name: logs
          mountPath: /app/logs

      volumes:
      - name: tmp
        emptyDir: {}
      - name: logs
        emptyDir: {}
```

--------------------------------------------------------------------------------

## 4.10 MEDIO: Log Rotation Faltante
- Archivo: docker-compose.yml
- Severidad: MEDIUM
- Categoría: Operations

PROBLEMA:
Logs pueden crecer indefinidamente.

CORRECCIÓN:
```yaml
# Agregar a TODOS los servicios:
services:
  api:
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
        labels: "service=ai-native-api"

  postgres:
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
        labels: "service=ai-native-postgres"

  redis:
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
        labels: "service=ai-native-redis"

  ollama:
    logging:
      driver: "json-file"
      options:
        max-size: "200m"  # LLM genera más logs
        max-file: "5"
        labels: "service=ai-native-ollama"
```

================================================================================
SECCIÓN 5: SCRIPTS DE MIGRACIÓN RECOMENDADOS
================================================================================

## 5.1 Migración de Base de Datos
```python
# backend/database/migrations/add_cortez3_fixes.py
"""
Cortez3 Audit - Database Fixes Migration
Aplica correcciones de FKs, índices y constraints identificados en auditoría.
"""
from sqlalchemy import text
from backend.database import get_db_engine

def upgrade():
    """Aplica correcciones de Cortez3."""
    engine = get_db_engine()

    with engine.begin() as conn:
        # 3.2 - Agregar CASCADE DELETE a FKs faltantes
        print("Adding CASCADE DELETE to ForeignKeys...")

        # InterviewSessionDB
        conn.execute(text("""
            ALTER TABLE interview_sessions
            DROP CONSTRAINT IF EXISTS interview_sessions_session_id_fkey;
        """))
        conn.execute(text("""
            ALTER TABLE interview_sessions
            ADD CONSTRAINT interview_sessions_session_id_fkey
            FOREIGN KEY (session_id) REFERENCES sessions(id) ON DELETE CASCADE;
        """))

        # IncidentSimulationDB
        conn.execute(text("""
            ALTER TABLE incident_simulations
            DROP CONSTRAINT IF EXISTS incident_simulations_session_id_fkey;
        """))
        conn.execute(text("""
            ALTER TABLE incident_simulations
            ADD CONSTRAINT incident_simulations_session_id_fkey
            FOREIGN KEY (session_id) REFERENCES sessions(id) ON DELETE CASCADE;
        """))

        # SimulatorEventDB
        conn.execute(text("""
            ALTER TABLE simulator_events
            DROP CONSTRAINT IF EXISTS simulator_events_session_id_fkey;
        """))
        conn.execute(text("""
            ALTER TABLE simulator_events
            ADD CONSTRAINT simulator_events_session_id_fkey
            FOREIGN KEY (session_id) REFERENCES sessions(id) ON DELETE CASCADE;
        """))

        # 3.4 - Agregar índices faltantes
        print("Adding missing indexes...")

        # Index en RiskDB (session_id, dimension)
        conn.execute(text("""
            CREATE INDEX IF NOT EXISTS idx_risk_session_dimension
            ON risks(session_id, dimension);
        """))

        # Index en CognitiveTraceDB activity_id
        conn.execute(text("""
            CREATE INDEX IF NOT EXISTS idx_trace_activity_id
            ON cognitive_traces(activity_id);
        """))

        # Index en RiskAlertDB assigned_to
        conn.execute(text("""
            CREATE INDEX IF NOT EXISTS idx_alert_assigned_to
            ON risk_alerts(assigned_to);
        """))

        # Index en CourseReportDB teacher_id
        conn.execute(text("""
            CREATE INDEX IF NOT EXISTS idx_report_teacher
            ON course_reports(teacher_id);
        """))

        # Index en RemediationPlanDB teacher_id
        conn.execute(text("""
            CREATE INDEX IF NOT EXISTS idx_plan_teacher
            ON remediation_plans(teacher_id);
        """))

        # 3.8 - Unique constraint en LTISessionDB
        print("Adding unique constraint to LTI sessions...")
        conn.execute(text("""
            CREATE UNIQUE INDEX IF NOT EXISTS idx_lti_unique_user_resource
            ON lti_sessions(deployment_id, lti_user_id, resource_link_id);
        """))

        print("Cortez3 database migration completed successfully!")

def rollback():
    """Revierte correcciones de Cortez3."""
    engine = get_db_engine()

    with engine.begin() as conn:
        # Revertir índices
        conn.execute(text("DROP INDEX IF EXISTS idx_risk_session_dimension;"))
        conn.execute(text("DROP INDEX IF EXISTS idx_trace_activity_id;"))
        conn.execute(text("DROP INDEX IF EXISTS idx_alert_assigned_to;"))
        conn.execute(text("DROP INDEX IF EXISTS idx_report_teacher;"))
        conn.execute(text("DROP INDEX IF EXISTS idx_plan_teacher;"))
        conn.execute(text("DROP INDEX IF EXISTS idx_lti_unique_user_resource;"))

        # Nota: No revertir CASCADE DELETE ya que es corrección de integridad
        print("Cortez3 database rollback completed!")

if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "rollback":
        rollback()
    else:
        upgrade()
```

================================================================================
SECCIÓN 6: CHECKLIST DE VERIFICACIÓN POST-REMEDIACIÓN
================================================================================

## Backend
[ ] 1.1 - execute_python_code() usa RestrictedPython
[ ] 1.2 - JWT_SECRET_KEY sin valor por defecto inseguro
[ ] 1.3 - Rate limiting en /exercises/submit
[ ] 1.4 - CORS methods/headers restringidos
[ ] 1.5 - Business logic extraída a services
[ ] 1.6 - Repositorios usan eager loading
[ ] 1.7 - List endpoints con paginación por defecto
[ ] 1.8 - Risk analysis en BackgroundTasks
[ ] 1.9 - Todos los endpoints usan APIResponse wrapper
[ ] 1.10 - Input validation con límites de tamaño

## Frontend
[ ] 2.1 - TutorPage dividido en componentes <200 líneas
[ ] 2.2 - AuthContext consolidado (eliminar duplicación)
[ ] 2.3 - Monaco Editor con lazy loading
[ ] 2.4 - extractErrorMessage() utility usado consistentemente
[ ] 2.5 - useCallback en todos los handlers
[ ] 2.6 - AbortSignal en todas las llamadas HTTP
[ ] 2.7 - Código del editor persistido en sessionStorage
[ ] 2.8 - Object literals memoizados con useMemo
[ ] 2.9 - Stats array memoizado

## Database
[ ] 3.1 - StudentProfileRepository creado
[ ] 3.2 - CASCADE DELETE en InterviewSession, IncidentSimulation, SimulatorEvent
[ ] 3.3 - ondelete explícito en SessionDB.user_id y RiskAlertDB.remediation_plan_id
[ ] 3.4 - Index idx_risk_session_dimension creado
[ ] 3.5 - Index idx_trace_activity_id creado
[ ] 3.6 - get_critical_risks() con selectinload anidado
[ ] 3.7 - get_by_student_activity_pairs() implementado
[ ] 3.8 - Unique constraint en LTISessionDB

## DevOps
[ ] 4.1 - Grafana credentials desde variables de entorno
[ ] 4.2 - Puerto 5432 solo en profile de desarrollo
[ ] 4.3 - Redis password en archivo de configuración (no command line)
[ ] 4.4 - /metrics endpoint con autenticación
[ ] 4.5 - Alert rules habilitadas en prometheus.yml
[ ] 4.6 - Network segmentation implementada
[ ] 4.7 - TLS con letsencrypt-prod en Kubernetes
[ ] 4.8 - start_period en Redis healthcheck
[ ] 4.9 - SecurityContext en Kubernetes pods
[ ] 4.10 - Log rotation configurada

================================================================================
FIN DEL REPORTE CORTEZ3
================================================================================
Próximos pasos:
1. Resolver TODOS los defectos CRÍTICOS antes de cualquier despliegue
2. Planificar sprint para defectos ALTOS
3. Agregar defectos MEDIOS y BAJOS al backlog técnico
4. Ejecutar migración add_cortez3_fixes.py
5. Actualizar CLAUDE.md con referencia a Cortez3
================================================================================
