# CORTEZ8: Audit de Consistencia ORM vs Pydantic vs API Schemas
# Fecha: 2025-12-12
# Auditor: Claude Code (Opus 4.5)
# Scope: Análisis de consistencia entre capas de datos

================================================================================
RESUMEN EJECUTIVO
================================================================================

Total de anomalías detectadas: 45
- CRITICAL: 6 (inconsistencias que causan errores en runtime)
- HIGH: 14 (inconsistencias que afectan funcionalidad)
- MEDIUM: 18 (inconsistencias que afectan mantenibilidad)
- LOW: 7 (mejoras de documentación y naming)

Capas analizadas:
- ORM (SQLAlchemy): backend/database/models.py
- Domain (Pydantic): backend/models/*.py
- API Schemas: backend/api/schemas/*.py

================================================================================
1. CRITICAL - ESCALA DE SCORES INCONSISTENTE
================================================================================

FIX 1.1 - EvaluationCreate.overall_score usa escala 0-1, ORM usa 0-10
  Ubicación:
    - API: backend/api/schemas/evaluation.py:24
    - ORM: backend/database/models.py:424
  Problema:
    API schema define: overall_score: float = Field(..., ge=0, le=1)
    ORM define: overall_score = Column(Float) con constraint 0-10
    Pydantic domain: overall_score: float = Field(ge=0.0, le=10.0)
  Impacto: Datos guardados con escala incorrecta, reportes con valores erróneos
  Solución: Cambiar API schema a escala 0-10:
    overall_score: float = Field(..., ge=0, le=10, description="Score general (0-10)")

FIX 1.2 - EvaluationDimensionScore.score usa escala 0-1, inconsistente con overall
  Ubicación: backend/api/schemas/evaluation.py:14
  Problema:
    EvaluationDimensionScore: score: float = Field(..., ge=0, le=1)
    Pero EvaluationDimension (Pydantic): score: float = Field(ge=0.0, le=10.0)
  Impacto: Dimensiones y overall usan escalas diferentes
  Solución: Unificar a escala 0-10 para consistencia:
    score: float = Field(..., ge=0, le=10, description="Score (0-10)")

FIX 1.3 - ProcessEvaluationResponse.overall_score usa escala incorrecta
  Ubicación: backend/api/schemas/evaluation.py:152
  Problema: Hereda el error de EvaluationCreate
  Solución: Cambiar a escala 0-10

FIX 1.4 - RiskAnalysis5DResponse.overall_score usa escala 0-100
  Ubicación: backend/api/schemas/risk.py:103
  Problema:
    overall_score: float = Field(..., ge=0, le=100)
    Pero RiskDimensionAnalysis usa escala 0-10
  Impacto: Inconsistencia interna en el mismo response
  Solución: Documentar claramente que overall es porcentaje (0-100) y dimension es (0-10)
    O unificar ambas a la misma escala

FIX 1.5 - SessionSummary.overall_score usa escala 0-1, inconsistente
  Ubicación: backend/api/schemas/session.py:226
  Problema:
    overall_score: Optional[float] = Field(None, description="Puntaje general (0-1)")
    Debería ser 0-10 para consistencia con evaluaciones
  Solución: Cambiar a 0-10 o documentar que es score normalizado

FIX 1.6 - Falta validación de rango en ORM para some scores
  Ubicación: backend/database/models.py
  Problema:
    TraceSequenceDB.ai_dependency_score tiene CheckConstraint (0-1) ✓
    StudentProfileDB.average_ai_dependency tiene CheckConstraint (0-1) ✓
    EvaluationDB.overall_score tiene CheckConstraint (0-10) ✓
    PERO: InterviewSessionDB.evaluation_score no tiene constraint de rango máximo
  Solución: Agregar constraint:
    CheckConstraint("evaluation_score IS NULL OR (evaluation_score >= 0 AND evaluation_score <= 1)")

================================================================================
2. HIGH - CAMPOS FALTANTES EN API SCHEMAS
================================================================================

FIX 2.1 - RiskResponse no expone campos del ORM
  Ubicación: backend/api/schemas/risk.py:43-80
  Campos faltantes en RiskResponse que existen en RiskDB:
    - root_cause: Text
    - impact_assessment: Text
    - trace_ids: JSON list
    - pedagogical_intervention: Text
    - detected_by: String(50)
  Solución: Agregar campos opcionales:
    root_cause: Optional[str] = Field(None, description="Causa raíz identificada")
    impact_assessment: Optional[str] = Field(None, description="Evaluación del impacto")
    trace_ids: List[str] = Field(default_factory=list, description="IDs de trazas relacionadas")
    pedagogical_intervention: Optional[str] = Field(None, description="Intervención pedagógica sugerida")
    detected_by: str = Field("AR-IA", description="Agente que detectó el riesgo")

FIX 2.2 - EvaluationResponse no expone ai_dependency_metrics
  Ubicación: backend/api/schemas/evaluation.py:66
  Problema:
    ORM EvaluationDB tiene: ai_dependency_metrics = Column(JSON, nullable=True)
    API EvaluationResponse no lo incluye
  Solución: Agregar:
    ai_dependency_metrics: Optional[Dict[str, Any]] = Field(None, description="Métricas detalladas de dependencia IA")

FIX 2.3 - SessionResponse no expone campos N4 de SessionDB
  Ubicación: backend/api/schemas/session.py:98
  Campos faltantes:
    - learning_objective: JSONB
    - cognitive_status: JSONB
    - session_metrics: JSONB
  Solución: Crear SessionDetailedResponse que incluya estos campos:
    learning_objective: Optional[Dict[str, Any]] = Field(None)
    cognitive_status: Optional[Dict[str, Any]] = Field(None)
    session_metrics: Optional[Dict[str, Any]] = Field(None)

FIX 2.4 - CognitiveTraceCreate no permite 6 dimensiones N4
  Ubicación: backend/api/schemas/trace.py:12-46
  Problema:
    ORM CognitiveTraceDB tiene 6 dimensiones N4:
      - semantic_understanding
      - algorithmic_evolution
      - cognitive_reasoning
      - interactional_data
      - ethical_risk_data
      - process_data
    API CognitiveTraceCreate solo permite campos básicos
  Solución: Agregar campos opcionales para las 6 dimensiones:
    semantic_understanding: Optional[Dict[str, Any]] = Field(None)
    algorithmic_evolution: Optional[Dict[str, Any]] = Field(None)
    cognitive_reasoning: Optional[Dict[str, Any]] = Field(None)
    interactional_data: Optional[Dict[str, Any]] = Field(None)
    ethical_risk_data: Optional[Dict[str, Any]] = Field(None)
    process_data: Optional[Dict[str, Any]] = Field(None)

FIX 2.5 - EvaluationDB.recommendations vs API split fields
  Ubicación:
    - ORM: backend/database/models.py:432 (recommendations = Column(JSON))
    - API: backend/api/schemas/evaluation.py:39-40 (recommendations_student, recommendations_teacher)
  Problema:
    ORM guarda un solo JSON "recommendations"
    API expone dos campos separados "recommendations_student" y "recommendations_teacher"
  Solución: O unificar en ORM o documentar el mapping en repository:
    # En repository al guardar:
    recommendations = {
        "student": create_data.recommendations_student,
        "teacher": create_data.recommendations_teacher
    }

FIX 2.6 - RiskCreate no tiene campo impact
  Ubicación: backend/api/schemas/risk.py:12-40
  Problema:
    ORM RiskDB tiene: impact = Column(Text, nullable=True)
    API RiskCreate no lo incluye
  Solución: Agregar:
    impact: Optional[str] = Field(None, description="Impacto potencial del riesgo")

FIX 2.7 - InteractionResponse falta parent_trace_id
  Ubicación: backend/api/schemas/interaction.py:193
  Problema:
    ORM CognitiveTraceDB tiene: parent_trace_id (para jerarquía de trazas)
    No se expone en ningún response de interacción
  Solución: Agregar cuando sea relevante (trazas con contexto padre)

FIX 2.8 - Falta schema para StudentProfileDB
  Ubicación: backend/api/schemas/ (no existe)
  Problema:
    ORM StudentProfileDB existe pero no hay API schemas correspondientes
  Solución: Crear backend/api/schemas/student_profile.py:
    class StudentProfileResponse(BaseModel):
        id: str
        student_id: str
        user_id: Optional[str]
        name: Optional[str]
        email: Optional[str]
        total_sessions: int
        total_interactions: int
        average_ai_dependency: float
        # ... etc

FIX 2.9 - Falta schema para ActivityDB
  Ubicación: backend/api/schemas/activity.py (existe pero incompleto)
  Problema: Verificar si ActivityDB fields están completamente mapeados
  Solución: Revisar y completar mapping

FIX 2.10 - Falta EvaluationResponse.student_id y activity_id
  Ubicación: backend/api/schemas/evaluation.py:66
  Problema:
    ORM EvaluationDB tiene: student_id, activity_id
    API EvaluationResponse no los incluye
  Solución: Agregar:
    student_id: str = Field(..., description="ID del estudiante")
    activity_id: str = Field(..., description="ID de la actividad")

FIX 2.11 - GitTraceDB Pydantic model falta campo cherry_pick
  Ubicación: backend/models/git_trace.py:20-28
  Problema:
    ORM GitTraceDB constraint incluye: 'cherry_pick' en event_type
    Pydantic GitEventType enum no incluye CHERRY_PICK
  Solución: Agregar:
    CHERRY_PICK = "cherry_pick"

FIX 2.12 - TraceSequence Pydantic no tiene activity_id requerido
  Ubicación: backend/models/trace.py:161-209
  Problema:
    ORM TraceSequenceDB tiene: activity_id = Column(String(100), nullable=False)
    Pydantic TraceSequence tiene: activity_id: str (requerido) ✓
  Estado: OK - Consistente

FIX 2.13 - RiskCreate.dimension usa RiskDimension enum con valores UPPERCASE
  Ubicación: backend/api/schemas/risk.py:20
  Problema:
    API usa: dimension: RiskDimension (valores: COGNITIVE, ETHICAL, etc.)
    ORM guarda lowercase: "cognitive", "ethical"
    Enums en schemas/enums.py usan lowercase values
  Estado: VERIFICADO - enums.py RiskDimension tiene values lowercase ("cognitive", etc.)
  No hay inconsistencia real

FIX 2.14 - Falta resolved_at en RiskCreate
  Ubicación: backend/api/schemas/risk.py:12
  Problema: No se puede crear un riesgo ya resuelto (edge case)
  Solución: OK para crear, se resuelve vía RiskResolveRequest

================================================================================
3. HIGH - NAMING INCONSISTENCIES
================================================================================

FIX 3.1 - timestamp vs created_at en responses
  Ubicación: Multiple schemas
  Problema:
    Pydantic domain models usan: timestamp: datetime
    API responses usan: created_at: datetime
    ORM usa: created_at (de BaseModel)
  Impacto: Confusión al mapear entre capas
  Archivos afectados:
    - backend/models/trace.py:119 (CognitiveTrace.timestamp)
    - backend/models/risk.py:68 (Risk.timestamp)
    - backend/models/evaluation.py:104 (EvaluationReport.timestamp)
  Solución: En Pydantic domain models, usar created_at para consistencia con ORM:
    created_at: datetime = Field(default_factory=datetime.now)
    # Mantener alias para backwards compatibility:
    class Config:
        populate_by_name = True
        fields = {'created_at': {'alias': 'timestamp'}}

FIX 3.2 - trace_metadata vs metadata
  Ubicación:
    - ORM: trace_metadata (SQLAlchemy reserved word conflict)
    - Pydantic: trace_metadata ✓
    - API: trace_metadata ✓
  Estado: CONSISTENTE después de Cortez7 - No requiere cambio

FIX 3.3 - competency_level vs overall_competency_level
  Ubicación:
    - ORM EvaluationDB: overall_competency_level
    - API EvaluationCreate: competency_level
    - Pydantic EvaluationReport: overall_competency_level
  Problema: Nombres diferentes para el mismo campo
  Solución: Unificar a overall_competency_level en API:
    overall_competency_level: str = Field(..., description="Nivel de competencia")

FIX 3.4 - evaluator_type no existe en ORM
  Ubicación: backend/api/schemas/evaluation.py:23
  Problema:
    API EvaluationCreate tiene: evaluator_type: str = Field("E-IA-PROC")
    ORM EvaluationDB no tiene este campo
  Solución:
    Opción A: Agregar campo a ORM
    Opción B: Remover de API (es siempre E-IA-PROC)
    Opción C: Guardar en metadata JSON

FIX 3.5 - mitigation en API vs recommendations en ORM
  Ubicación:
    - API RiskCreate: mitigation: Optional[str]
    - ORM RiskDB: recommendations = Column(JSON, default=list)
  Problema: Diferentes nombres y tipos
  Solución: Mapear mitigation -> recommendations en repository:
    if create_data.mitigation:
        db_risk.recommendations = [create_data.mitigation]

FIX 3.6 - metadata en RiskCreate vs no existe en RiskDB
  Ubicación: backend/api/schemas/risk.py:24
  Problema:
    API RiskCreate tiene: metadata: Optional[Dict[str, Any]]
    ORM RiskDB no tiene campo metadata
  Solución:
    Opción A: Agregar risk_metadata a ORM (consistente con trace_metadata)
    Opción B: Remover de API

================================================================================
4. MEDIUM - VALIDACIÓN INCONSISTENTE
================================================================================

FIX 4.1 - InteractionRequest tiene validadores, Pydantic domain no
  Ubicación: backend/api/schemas/interaction.py:14-177
  Observación:
    API schemas tienen validación robusta (UUID, prompt injection, size limits)
    Pydantic domain models confían en capa ORM
  Estado: ACEPTABLE - Validación en boundary layer es correcto

FIX 4.2 - String lengths no validados en Pydantic domain
  Ubicación: backend/models/*.py
  Problema:
    ORM define: String(100), String(36), String(255)
    Pydantic domain no tiene max_length validators
  Impacto: Posible truncación silenciosa o error de BD
  Solución: Agregar Field(max_length=X) donde corresponda:
    student_id: str = Field(..., max_length=100)
    session_id: str = Field(..., max_length=36)

FIX 4.3 - Faltan validators para UUIDs
  Ubicación: backend/models/*.py
  Problema:
    session_id debería ser UUID válido
    Solo InteractionRequest lo valida
  Solución: Crear validator reutilizable:
    from pydantic import field_validator
    import re

    UUID_PATTERN = r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$'

    @field_validator('session_id')
    def validate_uuid(cls, v):
        if not re.match(UUID_PATTERN, v, re.IGNORECASE):
            raise ValueError('Invalid UUID format')
        return v.lower()

FIX 4.4 - CognitiveState values inconsistentes entre capas
  Ubicación:
    - backend/models/trace.py:31-77 (CognitiveState con aliases)
    - backend/api/schemas/enums.py:121-142 (CognitiveState UPPERCASE)
  Problema:
    Múltiples valores mapean al mismo (e.g., EXPLORING, UNDERSTANDING -> "exploracion")
    Puede causar confusión en queries y reportes
  Solución:
    Ya existe COGNITIVE_STATE_API_TO_DB en trace.py
    Documentar claramente el flow: API UPPERCASE -> normalize -> DB lowercase

FIX 4.5 - InteractionType tiene valores mixtos
  Ubicación: backend/models/trace.py:18-28 vs backend/api/schemas/enums.py:144-168
  Problema:
    Domain model: valores lowercase (student_prompt, ai_response)
    API schema: valores UPPERCASE (QUESTION, RESPONSE) + lowercase aliases
  Solución:
    Ya existe INTERACTION_TYPE_API_TO_DB en enums.py
    Usar normalize_interaction_type() antes de guardar

FIX 4.6 - Falta validate_risk_type
  Ubicación: backend/api/schemas/risk.py:18
  Problema:
    risk_type: str (no enum, no validación)
    ORM acepta cualquier string hasta 100 chars
    Debería validar contra RiskType enum values
  Solución: Agregar validator:
    @field_validator('risk_type')
    def validate_risk_type(cls, v):
        valid_types = [e.value for e in RiskType]
        if v.lower() not in valid_types and v.upper() not in [e.name for e in RiskType]:
            raise ValueError(f'Invalid risk_type. Valid: {valid_types}')
        return v.lower()

FIX 4.7 - SessionCreate permite cualquier mode string
  Ubicación: backend/api/schemas/session.py:16
  Problema:
    mode: SessionMode (enum)
  Estado: CORRECTO - Ya usa enum para validación

FIX 4.8 - CognitiveTraceCreate.interaction_type es str, no enum
  Ubicación: backend/api/schemas/trace.py:22
  Problema:
    interaction_type: str = Field(...) # No usa InteractionType enum
  Solución: Cambiar a:
    interaction_type: Union[str, InteractionType] = Field(...)
    # O agregar validator

================================================================================
5. MEDIUM - CAMPOS OPCIONALES VS REQUERIDOS
================================================================================

FIX 5.1 - Risk.session_id es requerido pero RiskCreate no lo marca explícitamente
  Ubicación: backend/api/schemas/risk.py:15
  Estado: session_id: str = Field(...) con ellipsis = requerido
  Estado: CORRECTO

FIX 5.2 - EvaluationReport.reasoning_analysis cambiado a Optional
  Ubicación: backend/models/evaluation.py:109-111
  Observación: Ya documentado como Optional para alinear con ORM nullable=True
  Estado: CORRECTO

FIX 5.3 - GitTrace.activity_id inconsistente
  Ubicación:
    - Pydantic GitTrace: activity_id: str (requerido)
    - ORM GitTraceDB: activity_id = Column(String(100), nullable=False)
  Estado: CONSISTENTE

FIX 5.4 - InterviewSessionDB.activity_id es nullable
  Ubicación: backend/database/models.py:1096
  Problema:
    activity_id = Column(String(100), nullable=True)
    Pero en GitTraceDB es nullable=False
  Impacto: Inconsistencia conceptual
  Decisión: OK - Interview puede no estar asociada a actividad específica

FIX 5.5 - CourseReportDB.teacher_id es nullable
  Ubicación: backend/database/models.py:826
  Problema: Reporte sin teacher pierde accountability
  Decisión: OK con ondelete="SET NULL" para mantener reports si teacher es borrado

FIX 5.6 - LTISessionDB.session_id es nullable
  Ubicación: backend/database/models.py:1374
  Observación: Documentado como intencional (LTI launch antes de Session creation)
  Estado: CORRECTO - Bien documentado

================================================================================
6. MEDIUM - RELACIONES NO EXPUESTAS
================================================================================

FIX 6.1 - SessionResponse no incluye user info
  Ubicación: backend/api/schemas/session.py:98
  Problema:
    ORM SessionDB tiene: user = relationship("UserDB")
    API SessionResponse solo tiene: user_id: Optional[str]
  Solución: Crear SessionWithUserResponse que incluya user data embebido

FIX 6.2 - EvaluationResponse no incluye session info
  Ubicación: backend/api/schemas/evaluation.py:66
  Problema:
    ORM EvaluationDB tiene: session = relationship("SessionDB")
    API no expone datos de sesión
  Solución: Crear EvaluationDetailResponse con session data

FIX 6.3 - RiskResponse no incluye session data
  Similar a FIX 6.2

FIX 6.4 - Falta TraceSequenceResponse schema
  Ubicación: backend/api/schemas/ (no existe)
  Problema:
    ORM TraceSequenceDB existe
    Pydantic TraceSequence existe
    No hay API schema para responses
  Solución: Crear en trace.py:
    class TraceSequenceResponse(BaseModel):
        id: str
        session_id: str
        student_id: str
        activity_id: str
        start_time: datetime
        end_time: Optional[datetime]
        reasoning_path: List[str]
        strategy_changes: int
        ai_dependency_score: float
        trace_ids: List[str]
        created_at: datetime

FIX 6.5 - Falta endpoints para StudentProfile
  Observación: No hay router para student profiles
  Impacto: Datos de perfil no accesibles vía API

================================================================================
7. LOW - DOCUMENTACIÓN Y EXAMPLES
================================================================================

FIX 7.1 - json_schema_extra examples desactualizados
  Ubicación: Multiple schemas
  Problema: Examples no reflejan campos actuales
  Solución: Actualizar examples después de fixes

FIX 7.2 - Falta documentación de mappings API -> DB
  Solución: Agregar comentarios en schemas:
    # Maps to: ORM.field_name (transformation if any)

FIX 7.3 - Inconsistencia en description language
  Problema: Mezcla de español e inglés en descriptions
  Solución: Unificar a español (proyecto en español)

FIX 7.4 - Falta Type Aliases para IDs
  Solución: Crear types.py:
    from typing import Annotated
    SessionId = Annotated[str, Field(pattern=UUID_PATTERN)]
    StudentId = Annotated[str, Field(max_length=100)]

FIX 7.5 - Falta docstrings en algunos schemas
  Ubicación: Varios schemas sin docstring explicativo
  Solución: Agregar docstrings describiendo propósito

FIX 7.6 - Config class deprecated, usar model_config
  Ubicación: Multiple schemas usan class Config
  Problema: Pydantic v2 prefiere model_config = ConfigDict(...)
  Impacto: Warning en futuras versiones
  Solución: Migrar a:
    model_config = ConfigDict(
        from_attributes=True,
        json_schema_extra={...}
    )

FIX 7.7 - Falta schema para error responses
  Solución: Crear common.py:
    class ErrorResponse(BaseModel):
        success: bool = False
        message: str
        error_code: Optional[str] = None
        details: Optional[Dict[str, Any]] = None

================================================================================
8. RESUMEN DE ARCHIVOS A MODIFICAR
================================================================================

PRIORIDAD CRÍTICA:
1. backend/api/schemas/evaluation.py
   - FIX 1.1, 1.2, 1.3: Cambiar escalas de scores a 0-10
   - FIX 2.2, 2.10: Agregar campos faltantes
   - FIX 3.3, 3.4: Unificar nombres

2. backend/api/schemas/risk.py
   - FIX 1.4: Documentar escala
   - FIX 2.1, 2.6: Agregar campos faltantes
   - FIX 3.5, 3.6: Resolver naming

3. backend/api/schemas/session.py
   - FIX 1.5: Documentar escala
   - FIX 2.3: Agregar campos N4

PRIORIDAD ALTA:
4. backend/api/schemas/trace.py
   - FIX 2.4: Agregar 6 dimensiones N4
   - FIX 4.8: Usar enum para interaction_type

5. backend/models/trace.py
   - FIX 3.1: Usar created_at con alias timestamp

6. backend/models/risk.py
   - FIX 3.1: Usar created_at con alias timestamp

7. backend/models/evaluation.py
   - FIX 3.1: Usar created_at con alias timestamp

8. backend/models/git_trace.py
   - FIX 2.11: Agregar CHERRY_PICK a GitEventType

9. backend/database/models.py
   - FIX 1.6: Agregar constraint a evaluation_score

PRIORIDAD MEDIA:
10. backend/api/schemas/student_profile.py (CREAR)
    - FIX 2.8: Schemas para StudentProfileDB

11. backend/api/schemas/common.py
    - FIX 7.7: ErrorResponse schema

================================================================================
9. MIGRATION SCRIPT REQUERIDO
================================================================================

Los siguientes cambios requieren migración de datos existentes:

NINGUNO - Todos los fixes son de código, no de estructura de BD

================================================================================
10. TESTING RECOMENDADO
================================================================================

Después de aplicar fixes:

1. Unit tests para validators:
   - test_score_range_validation()
   - test_uuid_validation()
   - test_risk_type_validation()

2. Integration tests para mappings:
   - test_api_to_orm_evaluation_score()
   - test_api_to_orm_cognitive_state()
   - test_api_to_orm_interaction_type()

3. Regression tests:
   - test_existing_endpoints_still_work()
   - test_backwards_compatibility()

================================================================================
FIN DEL AUDIT CORTEZ8
================================================================================
